{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import gzip\n",
    "import tarfile\n",
    "import networkx as nx\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class CitationNetworkParser:\n",
    "    \"\"\"Parse cit-HepTh dataset and export citation network.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str = \"../data/raw\"):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.citations_file = self.data_dir / \"cit-HepTh.txt.gz\"\n",
    "        self.abstracts_file = self.data_dir / \"cit-HepTh-abstracts.tar.gz\"\n",
    "        self.graph = nx.DiGraph()\n",
    "        self.paper_metadata = {}\n",
    "        \n",
    "    def verify_files(self) -> None:\n",
    "        \"\"\"Verify required data files exist.\"\"\"\n",
    "        if not self.data_dir.exists():\n",
    "            raise FileNotFoundError(f\"Data directory not found: {self.data_dir}\")\n",
    "        \n",
    "        if not self.citations_file.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Citations file not found: {self.citations_file}\\n\"\n",
    "                f\"Please download 'cit-HepTh.txt.gz' and place it in {self.data_dir}\"\n",
    "            )\n",
    "        \n",
    "        if not self.abstracts_file.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Abstracts file not found: {self.abstracts_file}\\n\"\n",
    "                f\"Please download 'cit-HepTh-abstracts.tar.gz' and place it in {self.data_dir}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"✓ Found citations file: {self.citations_file}\")\n",
    "        print(f\"✓ Found abstracts file: {self.abstracts_file}\")\n",
    "    \n",
    "    def parse_citations(self) -> List[Tuple[str, str]]:\n",
    "        \"\"\"Parse citation edges from compressed file.\"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        print(\"Parsing citations...\")\n",
    "        with gzip.open(self.citations_file, 'rt') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 2:\n",
    "                        edges.append((parts[0], parts[1]))\n",
    "        \n",
    "        print(f\"Found {len(edges)} citations\")\n",
    "        return edges\n",
    "    \n",
    "    def parse_abstracts(self) -> None:\n",
    "        \"\"\"Extract paper metadata from tar.gz archive.\"\"\"\n",
    "        print(\"Extracting paper metadata...\")\n",
    "        \n",
    "        with tarfile.open(self.abstracts_file, 'r:gz') as tar:\n",
    "            for member in tar.getmembers():\n",
    "                if member.isfile() and member.name.endswith('.abs'):\n",
    "                    f = tar.extractfile(member)\n",
    "                    if f:\n",
    "                        content = f.read().decode('utf-8', errors='ignore')\n",
    "                        metadata = self._extract_metadata(content)\n",
    "                        \n",
    "                        if 'paper_id' in metadata:\n",
    "                            self.paper_metadata[metadata['paper_id']] = metadata\n",
    "        \n",
    "        print(f\"Extracted metadata for {len(self.paper_metadata)} papers\")\n",
    "    \n",
    "    def _extract_metadata(self, content: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract metadata fields from paper abstract file.\"\"\"\n",
    "        metadata = {}\n",
    "        \n",
    "        # Extract paper ID\n",
    "        paper_id_match = re.search(r'Paper:\\s*(\\S+)', content)\n",
    "        if paper_id_match:\n",
    "            metadata['paper_id'] = paper_id_match.group(1)\n",
    "        \n",
    "        # Extract title\n",
    "        title_match = re.search(r'Title:\\s*(.+?)(?=\\nAuthors?:|$)', content, re.DOTALL)\n",
    "        if title_match:\n",
    "            title = ' '.join(title_match.group(1).strip().split())\n",
    "            metadata['title'] = title\n",
    "        \n",
    "        # Extract authors\n",
    "        authors_match = re.search(r'Authors?:\\s*(.+?)(?=\\nComments?:|Abstract:|$)', content, re.DOTALL)\n",
    "        if authors_match:\n",
    "            authors = ' '.join(authors_match.group(1).strip().split())\n",
    "            metadata['authors'] = authors\n",
    "        \n",
    "        # Extract abstract\n",
    "        abstract_match = re.search(r'Abstract:\\s*(.+?)(?=\\\\\\\\|$)', content, re.DOTALL)\n",
    "        if abstract_match:\n",
    "            abstract = ' '.join(abstract_match.group(1).strip().split())\n",
    "            metadata['abstract'] = abstract\n",
    "        \n",
    "        return metadata\n",
    "    \n",
    "    def build_graph(self, edges: List[Tuple[str, str]]) -> None:\n",
    "        \"\"\"Build NetworkX graph with metadata.\"\"\"\n",
    "        print(\"Building graph...\")\n",
    "        \n",
    "        # Add edges\n",
    "        self.graph.add_edges_from(edges)\n",
    "        \n",
    "        # Add node attributes\n",
    "        for node in self.graph.nodes():\n",
    "            # Check both with and without 'hep-th/' prefix\n",
    "            if node in self.paper_metadata:\n",
    "                self.graph.nodes[node].update(self.paper_metadata[node])\n",
    "            else:\n",
    "                # Try with prefix\n",
    "                full_node_id = f\"hep-th/{node}\"\n",
    "                if full_node_id in self.paper_metadata:\n",
    "                    self.graph.nodes[node].update(self.paper_metadata[full_node_id])\n",
    "                else:\n",
    "                    # Default values if no metadata found\n",
    "                    self.graph.nodes[node]['paper_id'] = node\n",
    "                    self.graph.nodes[node]['title'] = f\"Paper {node}\"\n",
    "                    self.graph.nodes[node]['authors'] = ''\n",
    "                    self.graph.nodes[node]['abstract'] = ''\n",
    "        \n",
    "        print(f\"Graph built with {self.graph.number_of_nodes()} nodes and {self.graph.number_of_edges()} edges\")\n",
    "    \n",
    "    def export_csv(self, output_dir: str = \"../data/processed\") -> Tuple[Path, Path]:\n",
    "        \"\"\"Export nodes and edges as CSV files.\"\"\"\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Export nodes\n",
    "        nodes_data = []\n",
    "        for node in self.graph.nodes():\n",
    "            nodes_data.append({\n",
    "                'paper_id': node,\n",
    "                'title': self.graph.nodes[node].get('title', '')\n",
    "                # 'authors': self.graph.nodes[node].get('authors', ''),\n",
    "                # 'abstract': self.graph.nodes[node].get('abstract', '')\n",
    "            })\n",
    "        \n",
    "        nodes_df = pd.DataFrame(nodes_data)\n",
    "        nodes_csv = output_path / \"nodes.csv\"\n",
    "        nodes_df.to_csv(nodes_csv, index=False)\n",
    "        print(f\"Exported {len(nodes_df)} nodes to {nodes_csv}\")\n",
    "        \n",
    "        # Export edges\n",
    "        edges_data = [{'source': s, 'target': t} for s, t in self.graph.edges()]\n",
    "        \n",
    "        edges_df = pd.DataFrame(edges_data)\n",
    "        edges_csv = output_path / \"edges.csv\"\n",
    "        edges_df.to_csv(edges_csv, index=False)\n",
    "        print(f\"Exported {len(edges_df)} edges to {edges_csv}\")\n",
    "        \n",
    "        return nodes_csv, edges_csv\n",
    "    \n",
    "    def export_graphml(self, output_file: str = \"../data/processed/citation_network.graphml\") -> Path:\n",
    "        \"\"\"Export graph in GraphML format.\"\"\"\n",
    "        output_path = Path(output_file)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        nx.write_graphml(self.graph, str(output_path))\n",
    "        print(f\"Exported graph to {output_path}\")\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Parse citation network and export to CSV and GraphML formats.\"\"\"\n",
    "    parser = CitationNetworkParser()\n",
    "    \n",
    "    # Verify files exist\n",
    "    try:\n",
    "        parser.verify_files()\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Parse data\n",
    "    edges = parser.parse_citations()\n",
    "    parser.parse_abstracts()\n",
    "    \n",
    "    # Build graph\n",
    "    parser.build_graph(edges)\n",
    "    \n",
    "    # Export formats\n",
    "    parser.export_csv()\n",
    "    parser.export_graphml()\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "83d07f50ac77edc"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
