{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import json\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class EmbeddingSimilarityGraph:\n",
    "    \"\"\"Create similarity graphs from embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings: np.ndarray, paper_ids: Optional[list] = None):\n",
    "        \"\"\"\n",
    "        Initialize with embeddings.\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Array of shape (n_papers, embedding_dim)\n",
    "            paper_ids: Optional list of paper IDs\n",
    "        \"\"\"\n",
    "        self.embeddings = embeddings\n",
    "        self.paper_ids = paper_ids or list(range(len(embeddings)))\n",
    "        self.n_papers = len(embeddings)\n",
    "        self.similarity_matrix = None\n",
    "        \n",
    "        logging.info(f\"Initialized similarity graph with {self.n_papers} papers\")\n",
    "        logging.info(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "    \n",
    "    def compute_cosine_similarity(self) -> np.ndarray:\n",
    "        \"\"\"Compute cosine similarity matrix between all embeddings.\"\"\"\n",
    "        logging.info(\"Computing cosine similarity matrix...\")\n",
    "        self.similarity_matrix = cosine_similarity(self.embeddings)\n",
    "        logging.info(\"Cosine similarity matrix computed\")\n",
    "        return self.similarity_matrix\n",
    "\n",
    "    def get_knn_similarity_graph(self, k: int = 10) -> np.ndarray:\n",
    "        \"\"\"Get k-NN similarity graph to save memory.\"\"\"\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "        logging.info(f\"Creating k-NN similarity graph with k={k}\")\n",
    "\n",
    "        # Use NearestNeighbors to find k nearest neighbors efficiently\n",
    "        nbrs = NearestNeighbors(n_neighbors=k + 1, metric='cosine', n_jobs=-1)\n",
    "        nbrs.fit(self.embeddings)\n",
    "\n",
    "        # Get distances and indices\n",
    "        distances, indices = nbrs.kneighbors(self.embeddings)\n",
    "\n",
    "        # Convert distances to similarities (cosine distance = 1 - cosine similarity)\n",
    "        similarities = 1 - distances\n",
    "\n",
    "        # Create sparse affinity matrix\n",
    "        from scipy.sparse import lil_matrix\n",
    "        affinity_matrix = lil_matrix((self.n_papers, self.n_papers))\n",
    "\n",
    "        for i in range(self.n_papers):\n",
    "            for j_idx in range(1, k + 1):  # Skip first (self)\n",
    "                neighbor_idx = indices[i, j_idx]\n",
    "                similarity = similarities[i, j_idx]\n",
    "                # Make symmetric\n",
    "                affinity_matrix[i, neighbor_idx] = max(0, similarity)\n",
    "                affinity_matrix[neighbor_idx, i] = max(0, similarity)\n",
    "\n",
    "        # Convert to dense for spectral clustering\n",
    "        dense_matrix = affinity_matrix.toarray()\n",
    "        logging.info(\"Created k-NN similarity graph\")\n",
    "        return dense_matrix\n",
    "    \n",
    "    def get_full_similarity_graph(self) -> np.ndarray:\n",
    "        \"\"\"Get full similarity graph (all pairwise similarities).\"\"\"\n",
    "        if self.similarity_matrix is None:\n",
    "            self.compute_cosine_similarity()\n",
    "        \n",
    "        # Convert similarity to affinity (ensure positive values)\n",
    "        affinity_matrix = (self.similarity_matrix + 1) / 2  # Scale to [0, 1]\n",
    "        logging.info(\"Created full similarity graph\")\n",
    "        return affinity_matrix\n",
    "    \n",
    "    def get_graph_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get statistics about the similarity graph.\"\"\"\n",
    "        if self.similarity_matrix is None:\n",
    "            self.compute_cosine_similarity()\n",
    "            \n",
    "        stats = {\n",
    "            'n_papers': self.n_papers,\n",
    "            'embedding_dim': self.embeddings.shape[1],\n",
    "            'mean_similarity': float(np.mean(self.similarity_matrix)),\n",
    "            'std_similarity': float(np.std(self.similarity_matrix)),\n",
    "            'min_similarity': float(np.min(self.similarity_matrix)),\n",
    "            'max_similarity': float(np.max(self.similarity_matrix))\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "\n",
    "class SpectralClusteringPipeline:\n",
    "    \"\"\"Complete spectral clustering pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_clusters: int = 8, random_state: int = 42):\n",
    "        \"\"\"\n",
    "        Initialize clustering pipeline.\n",
    "        \n",
    "        Args:\n",
    "            n_clusters: Number of clusters to find\n",
    "            random_state: Random state for reproducibility\n",
    "        \"\"\"\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.clustering_model = None\n",
    "        self.cluster_labels = None\n",
    "        self.silhouette_avg = None\n",
    "        \n",
    "        logging.info(f\"Initialized spectral clustering with {n_clusters} clusters\")\n",
    "    \n",
    "    def fit_predict(self, affinity_matrix: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Fit spectral clustering and predict clusters.\n",
    "        \n",
    "        Args:\n",
    "            affinity_matrix: Precomputed affinity matrix\n",
    "            \n",
    "        Returns:\n",
    "            Cluster labels\n",
    "        \"\"\"\n",
    "        logging.info(\"Fitting spectral clustering...\")\n",
    "        \n",
    "        self.clustering_model = SpectralClustering(\n",
    "            n_clusters=self.n_clusters,\n",
    "            affinity='precomputed',\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        self.cluster_labels = self.clustering_model.fit_predict(affinity_matrix)\n",
    "        logging.info(\"Spectral clustering completed\")\n",
    "        \n",
    "        return self.cluster_labels\n",
    "    \n",
    "    def evaluate_clustering(self, embeddings: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate clustering using silhouette score.\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Original embeddings for evaluation\n",
    "            \n",
    "        Returns:\n",
    "            Silhouette score\n",
    "        \"\"\"\n",
    "        if self.cluster_labels is None:\n",
    "            raise ValueError(\"Must fit clustering first\")\n",
    "            \n",
    "        logging.info(\"Computing silhouette score...\")\n",
    "        self.silhouette_avg = silhouette_score(embeddings, self.cluster_labels)\n",
    "        logging.info(f\"Silhouette score: {self.silhouette_avg:.4f}\")\n",
    "        \n",
    "        return self.silhouette_avg\n",
    "    \n",
    "    def get_cluster_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get information about the clustering results.\"\"\"\n",
    "        if self.cluster_labels is None:\n",
    "            raise ValueError(\"Must fit clustering first\")\n",
    "            \n",
    "        unique_labels, counts = np.unique(self.cluster_labels, return_counts=True)\n",
    "        \n",
    "        cluster_info = {\n",
    "            'n_clusters': len(unique_labels),\n",
    "            'cluster_sizes': dict(zip(unique_labels.tolist(), counts.tolist())),\n",
    "            'silhouette_score': self.silhouette_avg,\n",
    "            'largest_cluster_size': int(np.max(counts)),\n",
    "            'smallest_cluster_size': int(np.min(counts)),\n",
    "            'mean_cluster_size': float(np.mean(counts)),\n",
    "            'std_cluster_size': float(np.std(counts))\n",
    "        }\n",
    "        \n",
    "        return cluster_info\n",
    "\n",
    "\n",
    "class ClusteringVisualizer:\n",
    "    \"\"\"Visualize clustering results.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str = \"results\"):\n",
    "        \"\"\"Initialize visualizer with output directory.\"\"\"\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    def plot_tsne_clusters(self, \n",
    "                          embeddings: np.ndarray, \n",
    "                          cluster_labels: np.ndarray,\n",
    "                          title: str = \"t-SNE Visualization of Clusters\",\n",
    "                          save_name: str = \"tsne_clusters.png\") -> None:\n",
    "        \"\"\"\n",
    "        Create t-SNE visualization of clusters.\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Original embeddings\n",
    "            cluster_labels: Cluster assignments\n",
    "            title: Plot title\n",
    "            save_name: Filename to save plot\n",
    "        \"\"\"\n",
    "        logging.info(\"Creating t-SNE visualization...\")\n",
    "        \n",
    "        # Compute t-SNE\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embeddings)//4))\n",
    "        embeddings_2d = tsne.fit_transform(embeddings)\n",
    "        \n",
    "        # Create plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                            c=cluster_labels, cmap='tab10', alpha=0.7)\n",
    "        plt.colorbar(scatter)\n",
    "        plt.title(title)\n",
    "        plt.xlabel('t-SNE Component 1')\n",
    "        plt.ylabel('t-SNE Component 2')\n",
    "        \n",
    "        # Save plot\n",
    "        save_path = self.output_dir / save_name\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        logging.info(f\"t-SNE plot saved to {save_path}\")\n",
    "    \n",
    "    def plot_cluster_sizes(self, \n",
    "                          cluster_info: Dict[str, Any],\n",
    "                          title: str = \"Cluster Size Distribution\",\n",
    "                          save_name: str = \"cluster_sizes.png\") -> None:\n",
    "        \"\"\"\n",
    "        Plot cluster size distribution.\n",
    "        \n",
    "        Args:\n",
    "            cluster_info: Cluster information dictionary\n",
    "            title: Plot title\n",
    "            save_name: Filename to save plot\n",
    "        \"\"\"\n",
    "        cluster_sizes = cluster_info['cluster_sizes']\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        clusters = list(cluster_sizes.keys())\n",
    "        sizes = list(cluster_sizes.values())\n",
    "        \n",
    "        plt.bar(clusters, sizes, alpha=0.7)\n",
    "        plt.xlabel('Cluster ID')\n",
    "        plt.ylabel('Number of Papers')\n",
    "        plt.title(title)\n",
    "        plt.xticks(clusters)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(sizes):\n",
    "            plt.text(clusters[i], v + 0.5, str(v), ha='center')\n",
    "        \n",
    "        # Save plot\n",
    "        save_path = self.output_dir / save_name\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        logging.info(f\"Cluster sizes plot saved to {save_path}\")\n",
    "\n",
    "\n",
    "class EmbeddingSpectralClusteringRunner:\n",
    "    \"\"\"Main runner for embedding-based spectral clustering.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 embeddings_file: str,\n",
    "                 n_clusters: int = 8,\n",
    "                 output_dir: str = \"results/milestone1\",\n",
    "                 random_state: int = 42):\n",
    "        \"\"\"\n",
    "        Initialize clustering runner.\n",
    "        \n",
    "        Args:\n",
    "            embeddings_file: Path to embeddings .npy file\n",
    "            n_clusters: Number of clusters\n",
    "            output_dir: Output directory for results\n",
    "            random_state: Random state for reproducibility\n",
    "        \"\"\"\n",
    "        self.embeddings_file = embeddings_file\n",
    "        self.n_clusters = n_clusters\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialize components\n",
    "        self.embeddings = None\n",
    "        self.paper_ids = None\n",
    "        self.similarity_graph = None\n",
    "        self.clustering_pipeline = None\n",
    "        self.visualizer = ClusteringVisualizer(str(self.output_dir))\n",
    "        \n",
    "        # Setup logging\n",
    "        self._setup_logging()\n",
    "        \n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Setup logging configuration.\"\"\"\n",
    "        log_file = self.output_dir / f\"clustering_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def load_embeddings(self):\n",
    "        \"\"\"Load embeddings from file.\"\"\"\n",
    "        logging.info(f\"Loading embeddings from {self.embeddings_file}\")\n",
    "        \n",
    "        embeddings_path = Path(self.embeddings_file)\n",
    "        if not embeddings_path.exists():\n",
    "            raise FileNotFoundError(f\"Embeddings file not found: {self.embeddings_file}\")\n",
    "        \n",
    "        self.embeddings = np.load(self.embeddings_file)\n",
    "        \n",
    "        # Try to load corresponding CSV file with paper IDs\n",
    "        csv_file = embeddings_path.with_suffix('.csv')\n",
    "        if csv_file.exists():\n",
    "            logging.info(f\"Loading paper IDs from {csv_file}\")\n",
    "            df = pd.read_csv(csv_file)\n",
    "            self.paper_ids = df['paper_id'].tolist()\n",
    "        else:\n",
    "            logging.warning(\"No CSV file found, using index as paper IDs\")\n",
    "            self.paper_ids = list(range(len(self.embeddings)))\n",
    "        \n",
    "        logging.info(f\"Loaded {len(self.embeddings)} embeddings with dimension {self.embeddings.shape[1]}\")\n",
    "    \n",
    "    def run_clustering(self) -> Dict[str, Any]:\n",
    "        \"\"\"Run complete clustering pipeline.\"\"\"\n",
    "        logging.info(\"Starting embedding-based spectral clustering pipeline...\")\n",
    "        \n",
    "        # Load embeddings\n",
    "        self.load_embeddings()\n",
    "        \n",
    "        # Create similarity graph\n",
    "        logging.info(\"Creating similarity graph...\")\n",
    "        self.similarity_graph = EmbeddingSimilarityGraph(self.embeddings, self.paper_ids)\n",
    "        affinity_matrix = self.similarity_graph.get_knn_similarity_graph()\n",
    "        \n",
    "        # Run spectral clustering\n",
    "        logging.info(\"Running spectral clustering...\")\n",
    "        self.clustering_pipeline = SpectralClusteringPipeline(\n",
    "            n_clusters=self.n_clusters,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        cluster_labels = self.clustering_pipeline.fit_predict(affinity_matrix)\n",
    "        silhouette_score = self.clustering_pipeline.evaluate_clustering(self.embeddings)\n",
    "        \n",
    "        # Get results\n",
    "        graph_stats = self.similarity_graph.get_graph_statistics()\n",
    "        cluster_info = self.clustering_pipeline.get_cluster_info()\n",
    "        \n",
    "        # Create visualizations\n",
    "        logging.info(\"Creating visualizations...\")\n",
    "        self.visualizer.plot_tsne_clusters(\n",
    "            self.embeddings, \n",
    "            cluster_labels,\n",
    "            title=\"t-SNE Visualization of Embedding-based Clusters\"\n",
    "        )\n",
    "        self.visualizer.plot_cluster_sizes(cluster_info)\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            'method': 'embedding_spectral_clustering',\n",
    "            'graph_type': 'knn-similarity',\n",
    "            'n_clusters': self.n_clusters,\n",
    "            'n_papers': len(self.embeddings),\n",
    "            'embedding_dim': self.embeddings.shape[1],\n",
    "            'silhouette_score': silhouette_score,\n",
    "            'graph_statistics': graph_stats,\n",
    "            'cluster_info': cluster_info,\n",
    "            'embeddings_file': str(self.embeddings_file),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Save results\n",
    "        self._save_results(results, cluster_labels)\n",
    "        \n",
    "        logging.info(\"Clustering pipeline completed successfully!\")\n",
    "        return results\n",
    "\n",
    "    def _save_results(self, results: Dict[str, Any], cluster_labels: np.ndarray):\n",
    "        \"\"\"Save clustering results to files.\"\"\"\n",
    "\n",
    "        # Convert numpy types to Python native types for JSON serialization\n",
    "        def convert_numpy_types(obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, dict):\n",
    "                return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [convert_numpy_types(item) for item in obj]\n",
    "            else:\n",
    "                return obj\n",
    "\n",
    "        # Convert results to JSON-serializable format\n",
    "        json_results = convert_numpy_types(results)\n",
    "        results_file = self.output_dir / \"clustering_results.json\"\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(json_results, f, indent=2)\n",
    "        logging.info(f\"Results saved to {results_file}\")\n",
    "        \n",
    "        # Save cluster assignments\n",
    "        cluster_assignments = pd.DataFrame({\n",
    "            'paper_id': self.paper_ids,\n",
    "            'cluster': cluster_labels\n",
    "        })\n",
    "        \n",
    "        assignments_file = self.output_dir / \"cluster_assignments.csv\"\n",
    "        cluster_assignments.to_csv(assignments_file, index=False)\n",
    "        logging.info(f\"Cluster assignments saved to {assignments_file}\")\n",
    "        \n",
    "        # Save summary\n",
    "        summary_file = self.output_dir / \"clustering_summary.txt\"\n",
    "        with open(summary_file, 'w') as f:\n",
    "            f.write(\"Embedding-based Spectral Clustering Results\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"Embeddings file: {self.embeddings_file}\\n\")\n",
    "            f.write(f\"Number of papers: {results['n_papers']}\\n\")\n",
    "            f.write(f\"Embedding dimension: {results['embedding_dim']}\\n\")\n",
    "            f.write(f\"Number of clusters: {results['n_clusters']}\\n\")\n",
    "            f.write(f\"Silhouette score: {results['silhouette_score']:.4f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Graph Statistics:\\n\")\n",
    "            for key, value in results['graph_statistics'].items():\n",
    "                f.write(f\"  {key}: {value}\\n\")\n",
    "            \n",
    "            f.write(f\"\\nCluster Information:\\n\")\n",
    "            for key, value in results['cluster_info'].items():\n",
    "                f.write(f\"  {key}: {value}\\n\")\n",
    "        \n",
    "        logging.info(f\"Summary saved to {summary_file}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run embedding-based spectral clustering.\"\"\"\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description=\"Run spectral clustering on embeddings\")\n",
    "    parser.add_argument(\n",
    "        \"--embeddings-file\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to embeddings .npy file\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--n-clusters\",\n",
    "        type=int,\n",
    "        default=8,\n",
    "        help=\"Number of clusters\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output-dir\",\n",
    "        type=str,\n",
    "        default=\"results/milestone1\",\n",
    "        help=\"Output directory for results\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--random-state\",\n",
    "        type=int,\n",
    "        default=42,\n",
    "        help=\"Random state for reproducibility\"\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Run clustering\n",
    "    runner = EmbeddingSpectralClusteringRunner(\n",
    "        embeddings_file=args.embeddings_file,\n",
    "        n_clusters=args.n_clusters,\n",
    "        output_dir=args.output_dir,\n",
    "        random_state=args.random_state\n",
    "    )\n",
    "    \n",
    "    results = runner.run_clustering()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EMBEDDING-BASED SPECTRAL CLUSTERING COMPLETED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Silhouette Score: {results['silhouette_score']:.4f}\")\n",
    "    print(f\"Number of clusters: {results['n_clusters']}\")\n",
    "    print(f\"Number of papers: {results['n_papers']}\")\n",
    "    print(f\"Results saved to: {args.output_dir}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "89bf77b535bb3341"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
